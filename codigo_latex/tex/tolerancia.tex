\section{Tolerancia a Fallas}

\subsection{Introducción}

En esta sección se detallan los mecanismos implementados en el Sistema Distribuido para tolerar distintos escenarios de falla.  
El objetivo principal de estas implementaciones es garantizar la \textbf{consistencia} y la \textbf{robustez} del sistema, priorizando estos atributos por sobre la eficiencia en términos de rendimiento.

En cuanto a la arquitectura general, no se presentan modificaciones en la topología previamente documentada.  
El único agregado corresponde a la incorporación de un conjunto de nodos denominados \textit{Health Checkers}, encargados de consultar de forma recurrente el estado de cada nodo del sistema, con el fin de validar su correcto funcionamiento o, en caso de detectar fallas, iniciar procesos de recuperación para restablecer las instancias caídas.

\subsection{Health Checkers}

Los nodos \textit{Health Checkers} se encargan de monitorear continuamente que todos los nodos encargados del procesamiento para la generación de resultados se encuentren activos.  
Este mecanismo está implementado mediante múltiples instancias dispuestas en una topología en anillo, con el fin de garantizar la tolerancia a fallas y la alta disponibilidad del propio sistema de monitoreo.

Uno de los nodos cumple el rol de \textbf{Líder}, siendo el responsable de coordinar las validaciones periódicas.  
En caso de que el líder falle, se ejecuta automáticamente un algoritmo de elección que designa un nuevo líder, el cual retoma las tareas del anterior.

El proceso de verificación consiste en el envío periódico de mensajes de tipo \textit{Ping} a cada nodo del sistema.  
Si el nodo responde con un \textit{ACK}, se considera activo; en caso contrario, el líder inicia el proceso de recuperación de esa instancia.

\subsubsection{Topología del Sistema de Health Checkers}

A continuación se deja un diagrama que representa la topología del \textbf{Sistema de Health Checkers}, donde se representa tanto la lógica de
topología de anillo, como la función del \textbf{Líder} y un ejemplo de funcionamiento al hacer \textit{Ping} a diversos \textit{Cleaners}.

\vspace{0.5cm}

\FloatBarrier
\begin{figure}[H]
  \centering
  \includegraphics[scale=0.22, keepaspectratio]{health.png}
  \caption{Topología del Sistema de Health Checkers}
  \label{fig:healthcheckers}
\end{figure}

\newpage

\subsection{Cambio de comportamiento en los nodos}

Se introdujeron modificaciones significativas en el funcionamiento de todos los nodos del sistema que consumen mensajes desde las colas de \textit{RabbitMQ}.  
El objetivo de estos cambios es fortalecer la robustez del sistema ante fallas parciales y garantizar la consistencia de los datos en todo momento.

Cada nodo, al recibir (``popear'') un mensaje desde la cola correspondiente, ejecuta su lógica de procesamiento, le envía el mensaje a la siguiente cola de el próximo nodo, escribe el mensaje o el estado actualizado en su volumen persistente, y finalmente envía el \textit{ACK} a \textit{RabbitMQ}.  
Este orden de operaciones —procesamiento, envío, persistencia y confirmación— es esencial para evitar duplicaciones o pérdidas de mensajes ante fallas inesperadas.  

Gracias a la semántica de confirmación de \textit{RabbitMQ}, si un mensaje es consumido pero no se envía el \textit{ACK}, dicho mensaje se reencola automáticamente al inicio de la cola.  
De esta forma, ante una caída, el nodo podrá retomar su ejecución desde el último estado persistido o reprocesar el mensaje que quedó pendiente, garantizando así la consistencia del flujo.

\textbf{Observación:}  
Todos los archivos generados se almacenan en volúmenes persistentes asociados a los contenedores de cada nodo.  
Esto permite que, incluso tras una caída o reinicio, el nodo conserve su información y pueda recuperar su estado previo sin pérdida de datos.

\subsubsection{Nodos Stateless}

Los nodos \textit{Stateless} procesan mensajes de manera independiente, sin mantener un estado acumulativo entre ellos.  
Su flujo de ejecución se compone de las siguientes etapas:

\begin{enumerate}
    \item Recepción del mensaje desde la cola de entrada.
    \item Procesamiento del mensaje (limpieza, filtrado u otra operación específica).
    \item Envío del resultado al siguiente nodo.
    \item Escritura del mensaje procesado en un archivo local del volumen persistente, para disponer de una copia de respaldo.
    \item Envío del \textit{ACK} a \textit{RabbitMQ}.
\end{enumerate}

La escritura en disco se realiza \textbf{únicamente al final del proceso}, luego de haber enviado el mensaje.  
Este orden es crítico, ya que evita que un mensaje pueda ser reenviado o computado más de una vez, garantizando la consistencia global del sistema.

\subsubsection{Nodos Stateful (Joins)}

Los nodos \textit{Joins} presentan un comportamiento intermedio entre los nodos con y sin estado.  
Durante su ejecución inicial, reciben información de configuración proveniente del servidor, la cual se almacena en su volumen local y se utiliza de manera incremental al procesar los siguientes mensajes.

Una vez recibida toda la información del servidor, el nodo pasa a comportarse de forma análoga a un nodo \textit{Stateless}:  
procesa, envía, registra y confirma cada mensaje de manera independiente.

Para facilitar la recuperación ante fallas, una vez completada la fase de inicialización, el nodo \textit{Join} registra un indicador distintivo (por ejemplo, una marca de finalización) en su archivo local.  
De esta forma, si el nodo se reinicia, puede detectar fácilmente si ya recibió todos los datos del servidor o si aún resta información por almacenar.

\newpage

\subsubsection{Nodos Stateful con estado acumulativo (Sorts, Sums, Counts)}

\textbf{Funcionamiento inicial del nodo}

Los nodos con estado acumulativo —como \textit{Sorts}, \textit{Sums} y \textit{Counts}— mantienen información agregada entre mensajes.  
Su comportamiento fue rediseñado para maximizar la confiabilidad y optimizar la recuperación ante fallas.

Cada nodo sigue el siguiente flujo:

\begin{enumerate}
    \item Recibe un mensaje desde la cola correspondiente.
    \item Actualiza su estado interno con la información del mensaje (operación de cómputo o agregación).
    \item Escribe el mensaje procesado en su archivo local (uno por cada nodo antecesor).
    \item Envía el \textit{ACK} a \textit{RabbitMQ}.
    \item Continúa con el siguiente mensaje.
\end{enumerate}

Cada cierto número de mensajes $n$, configurable según la carga del nodo o la probabilidad de falla estimada, se realiza un \textbf{backup o checkpoint} del estado actual.  
Este se guarda en un archivo separado dentro del mismo volumen, y actúa como punto de restauración ante fallas.

\textbf{Envío del reporte generado hacia el próximo nodo}

Finalmente, una vez completado el procesamiento de todos los mensajes correspondientes a una consulta o cliente, el nodo realiza el cálculo del estado final acumulado.  
Antes de enviarlo al siguiente nodo de la secuencia, dicho estado se escribe en el archivo de \textbf{backup/checkpoint}, garantizando la persistencia del resultado más reciente.

Posteriormente, se procede al envío del estado al nodo siguiente.  
Una vez completado este envío, el nodo registra en su volumen una marca o indicador que señala que el estado correspondiente a esa consulta o cliente ya fue transmitido correctamente.  
Esto permite que, en caso de una caída y posterior recuperación, el nodo identifique que el resultado ya fue enviado y evite duplicaciones o recomputaciones innecesarias.

En los casos en que el envío del estado final requiera dividir la información en múltiples mensajes, se aplica la misma lógica de procesamiento y persistencia que para el resto de los mensajes:  
cada fragmento enviado se escribe previamente en un volumen dedicado al manejo de dichos estados parciales, asegurando un control preciso de la consistencia y la trazabilidad del proceso completo.

\textbf{Consideraciones}

Para mantener el uso eficiente del almacenamiento, tras cada backup se eliminan o marcan los registros previos como \textit{COMMIT}, indicando que los mensajes anteriores ya fueron computados y persistidos en el estado actual.

Cada nodo mantiene archivos separados por cada uno de sus antecesores.  
Esto permite acceder de manera directa al último mensaje procesado por cada fuente, manteniendo la trazabilidad y la consistencia del flujo completo.  
Se asume además que todas las escrituras en disco son \textbf{atómicas}, garantizando que sólo existen dos posibles resultados: escritura completa o ausencia total de la misma, eliminando la posibilidad de estados intermedios inconsistentes.

\newpage

\subsection{Cambios en el protocolo}

La nueva implementación introduce un encabezado (\textit{header}) ligero que se agrega sobre el paquete existente, siguiendo un enfoque análogo al apilado de cabeceras entre capas de enlace y red en redes tradicionales. Este encabezado incorpora dos campos adicionales:

\begin{itemize}
  \item \textbf{UUID del mensaje} (\texttt{msg\_uuid}): Generado por el servidor emisor inicial y \textit{consistente durante toda la vida del mensaje} a través de la tubería de procesamiento. En los nodos que generan reportes/outputs finales, se genera un \textit{nuevo} UUID para el artefacto resultante, el cual se usa a partir de ahí para su trazabilidad.
  \item \textbf{Identificador del nodo origen} (\texttt{src\_node\_id}): Indica el nodo que produjo el mensaje. Se utiliza en el receptor para dirigir la persistencia al volumen/archivo correspondiente a ese origen, preservando trazabilidad y consistencia.
\end{itemize}

\FloatBarrier
\begin{figure}[H]
  \centering
  \includegraphics[scale=0.18, keepaspectratio]{mensajes.png}
  \caption{Estructura de los mensajes}
  \label{fig:estructura_mensajes}
\end{figure}

\paragraph{Balanceo determinista basado en hash}
Los nodos que antes distribuían carga con \textit{Round Robin} (contador) migran a \textbf{hash por \texttt{msg\_uuid}}. Este cambio evita desbalances e inconsistencias cuando un nodo cae y reinicia su contador:
\begin{itemize}
  \item Con \textit{Round Robin}, un reinicio cambia el punto del ciclo y el mismo mensaje podría enrutarse a un destino distinto.
  \item Con \textbf{hash(msg\_uuid)}, a igual UUID se obtiene el mismo destino (consistentemente), incluso si el nodo se reinicia. Esto preserva afinidad de mensaje y localización esperada del estado.
\end{itemize}

\paragraph{Compatibilidad y consistencia}
El encabezado es aditivo, no rompe el formato del payload previo. La escritura local sigue siendo atómica, y la lógica de ACK de \textit{RabbitMQ} permanece inalterada: el ACK sólo se emite cuando el procesamiento y la persistencia asociada se completan, manteniendo idempotencia extremo a extremo.

\newpage

\subsection{Escenarios de Falla}

A continuación se detallan los distintos escenarios de falla contemplados durante el diseño de los mecanismos de tolerancia y recuperación del sistema.  
En todos los casos, se garantiza tanto la continuidad operativa ante la caída de uno o más nodos, como la consistencia de los resultados y del flujo de mensajes.

\subsubsection{Falla en los Health Checkers}

Ante la caída de algún nodo del sistema de \textit{Health Checkers}, pueden presentarse dos situaciones:

\begin{itemize}
    \item \textbf{Falla del líder:}  
    Se ejecuta un proceso de elección para designar un nuevo líder, el cual se reconecta con los nodos activos del sistema y retoma las tareas pendientes.

    \item \textbf{Falla de un nodo no líder:}  
    La instancia se remueve temporalmente del anillo para mantener la coherencia de la topología.
\end{itemize}

En ambos casos, se intenta levantar nuevamente la instancia caída para restablecer el nivel de redundancia definido y mantener la alta disponibilidad del sistema.

\subsubsection{Falla en los Nodos Stateless y Nodos Join}

El comportamiento ante fallas es similar al de los nodos \textit{Join}:

\begin{itemize}
    \item \textbf{Falla antes del \textit{ACK}:}  
    \textit{RabbitMQ} reencola el mensaje, que será procesado nuevamente cuando el nodo se recupere.
    Como esta es la última operación antes de popear otro mensaje, no existe otro instante de falla a considerar.
\end{itemize}

\subsubsection{Falla en los Nodos Statefull}

Dependiendo del tipo de nodo, los mecanismos de recuperación difieren:

\paragraph{Nodos con estado acumulativo (Sorts, Sums, Counts):}
\begin{itemize}
    \item \textbf{Si el nodo falla antes de procesar el mensaje}:  
    El mensaje se reencola automáticamente por \textit{RabbitMQ}, y al reiniciarse, el nodo lo vuelve a procesar desde su archivo o desde el backup más reciente.

    \item \textbf{Si falla después de procesar el mensaje pero antes del \textit{ACK}}:  
    El mensaje se reencola, y al recuperarse, el nodo detecta en su registro que el mensaje ya fue computado, evitando duplicaciones.

    \item \textbf{Si falla durante la acumulación}:  
    Al reiniciarse, el nodo restaura su estado desde el último backup disponible y continúa procesando desde el siguiente mensaje.

    \item \textbf{Si falla en el proceso de envío del reporte hacia el próximo nodo}:  
    Al volver a despertar, se retoma desde el último mensaje enviado, para garantizar la consistencia del sistema, evitando mensajes duplicados.
    Para identificar los mensajes, el nodo que genera el reporte asigna los IDs correspondientes, haciendose responsable de su correctitud.
\end{itemize}

\newpage

\subsubsection{Fallas Desestimadas}

Durante el análisis se identificaron otros posibles tipos de falla:

\begin{itemize}
    \item Falla en el \textbf{Servidor Central}.
    \item Falla en los \textbf{Clientes}.
    \item Falla en el \textbf{Middleware RabbitMQ}.
\end{itemize}

El manejo de estos escenarios fue desestimado en esta versión del sistema, dado que implicaría definir contratos adicionales con los clientes y un nivel de complejidad que excede los requerimientos del presente enunciado.  

Sin embargo, se documentan estos casos para su consideración en futuras versiones del sistema.

\subsubsection{Mecanismos adicionales de consistencia}

Para garantizar la coherencia incluso en escenarios de fallas simultáneas:
\begin{itemize}
    \item El nodo siguiente a uno caído valida que los mensajes recibidos no sean duplicados, comparando el último mensaje recibido con el nuevo.
    \item Los nodos que mantienen estado lo recomponen desde su último backup; los que no, reprocesan los mensajes pendientes desde la cola.
    \item Dado que \textit{RabbitMQ} no pierde mensajes durante las caídas, el sistema mantiene su integridad global.
\end{itemize}

\subsection{Sistema de Generación de Errores}

Con el objetivo de validar los mecanismos de tolerancia a fallas implementados en el sistema, se desarrolló un \textbf{Sistema de Generación de Errores}, diseñado para simular distintos escenarios de falla de manera controlada o aleatoria.

Este sistema cuenta con dos funcionalidades principales:

\begin{itemize}
    \item \textbf{Inyección manual de fallas en instancias específicas:}  
    Esta herramienta permite provocar la caída de instancias puntuales del sistema de forma controlada.  
    Su propósito principal es facilitar las pruebas durante el desarrollo, permitiendo analizar el comportamiento del sistema ante la falla y posterior recuperación de nodos concretos, así como verificar la consistencia de los datos y estados luego de cada reinicio.

    \item \textbf{Módulo de fallas aleatorias tipo \textit{Chaos Monkey}:}  
    Inspirado en las prácticas de ingeniería del caos, este módulo genera caídas y perturbaciones de manera aleatoria en distintas partes del sistema.  
    De esta forma, se evalúa el comportamiento integral del sistema distribuido bajo condiciones de falla no determinísticas, más cercanas a un entorno real de producción.  
    Este enfoque permite demostrar la robustez global y la correcta recuperación de los componentes frente a fallas imprevistas.
\end{itemize}

La señal que envía el sistema de generación de fallas a los nodos vivos es \textbf{SIGKILL}. 

En conjunto, ambas funcionalidades permiten validar tanto el funcionamiento individual de los mecanismos de tolerancia a fallas como su efectividad a nivel global, asegurando la resiliencia y estabilidad del sistema frente a distintos tipos de incidentes.

\newpage

\subsection{Mediciones de Rendimiento (Con Fallas)}

Con el objetivo de evaluar el comportamiento y la eficiencia del sistema distribuido, se realizaron diversas mediciones de rendimiento bajo distintos escenarios y volúmenes de datos.  
El propósito de este análisis es determinar la capacidad del sistema para mantener la consistencia de los resultados y la estabilidad de los tiempos de respuesta ante la presencia de fallas controladas o aleatorias.

Las pruebas se dividen en dos grupos principales: aquellas realizadas sobre un \textbf{dataset reducido}, orientadas a validar la consistencia frente a fallas aleatorias, y aquellas efectuadas sobre el \textbf{dataset completo}, destinadas a medir la performance global del sistema con y sin eventos de falla.

\subsubsection{Dataset Reducido: Consistencia frente a caídas aleatorias}

En este conjunto de pruebas se busca demostrar que el sistema mantiene resultados consistentes ante la ocurrencia de fallas aleatorias, validando así la efectividad de los mecanismos de tolerancia a fallas implementados.

\paragraph{Herramienta de evaluación}
Para la ejecución de estas pruebas se empleará el \textbf{Sistema de Generación de Errores} previamente descripto, en su modo de funcionamiento aleatorio tipo \textit{Chaos Monkey}.  
Esta herramienta permitirá simular caídas no determinísticas de distintas instancias del sistema, abarcando tanto nodos \textit{stateless} como \textit{stateful} y componentes del anillo de \textit{Health Checkers}.

\paragraph{Parámetros de prueba}
Los principales parámetros de configuración de las pruebas son los siguientes (valores a definir en futuras iteraciones):

\begin{itemize}
    \item Frecuencia de generación de fallas: \texttt{X segundos}.
    \item Duración total de la prueba: \texttt{X minutos}.
    \item Cantidad de nodos involucrados: \texttt{X}.
    \item Tipos de nodos afectados: \texttt{Stateful / Stateless / Health Checker}.
    \item Volumen de datos procesado: \texttt{X Gb}.
\end{itemize}

\paragraph{Criterios de evaluación}
Los criterios utilizados para validar la consistencia y estabilidad del sistema serán:

\begin{itemize}
    \item Coincidencia de los resultados obtenidos con los esperados (control de consistencia).
    \item Tiempo promedio de recuperación ante fallas.
    \item Número de tareas reintentadas correctamente.
    \item Impacto en la latencia promedio del sistema.
\end{itemize}

\paragraph{Resultados esperados}
Se espera observar resultados consistentes en la salida final, independientemente de las caídas aleatorias introducidas, y una recuperación rápida de las instancias afectadas.  
Los valores numéricos y métricas específicas serán completados una vez finalizada la ejecución de las pruebas.

\newpage

\subsubsection{Dataset Completo: Monitoreo de performance con y sin fallas}

Este conjunto de pruebas se orienta a analizar el rendimiento del sistema distribuido bajo carga completa, tanto en condiciones estables (sin fallas) como durante la inyección de fallas aleatorias, con el fin de evaluar la degradación del desempeño.

\paragraph{Herramienta y entorno de medición}
Las mediciones se realizarán utilizando herramientas de monitoreo de recursos y trazabilidad, tales como \texttt{Prometheus}, \texttt{Grafana} o equivalentes (a definir).  
Estas permitirán recolectar métricas en tiempo real sobre el consumo de CPU, memoria, tráfico de red y latencia promedio de las consultas distribuidas.

\paragraph{Parámetros de prueba}
Los principales parámetros definidos para este escenario son los siguientes (valores a completar):

\begin{itemize}
    \item Tamaño del dataset completo: \texttt{X Gb}.
    \item Cantidad total de nodos en ejecución: \texttt{X}.
    \item Cantidad de consultas simultáneas: \texttt{X}.
    \item Duración de la medición: \texttt{X minutos}.
    \item Inyección de fallas aleatorias: \texttt{Sí / No}.
\end{itemize}

\paragraph{Criterios de evaluación}
Las métricas principales a analizar serán:

\begin{itemize}
    \item Tiempo promedio de procesamiento por consulta.
    \item Throughput del sistema (consultas por segundo).
    \item Utilización promedio de recursos (CPU, memoria, red).
    \item Variación del rendimiento ante la presencia de fallas.
\end{itemize}

\paragraph{Resultados esperados}
Se espera observar un desempeño estable del sistema bajo carga completa en condiciones normales, con una degradación controlada durante las pruebas con fallas aleatorias.  
Los resultados cuantitativos y gráficos comparativos serán incorporados una vez completadas las mediciones experimentales.
