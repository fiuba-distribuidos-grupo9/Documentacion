\section{Middleware}

El middleware interno constituye el pilar fundamental de la comunicación en el sistema \textit{Coffee Shop Analysis}, siendo el responsable de orquestar la interacción entre el servidor central y los múltiples nodos de procesamiento. Su arquitectura se basa en un modelo de Middleware Orientado a Mensajes (MOM), implementado mediante la herramienta \textbf{RabbitMQ}, que actúa como bróker central y mediador confiable entre los distintos procesos distribuidos, tal como se visualiza en el Diagrama de Despliegue.  

La adopción de un middleware de este tipo permite abstraer completamente la complejidad de la comunicación en red, ocultando al programador los detalles de bajo nivel relacionados con sockets, serialización de datos o control de concurrencia. En lugar de conexiones rígidas punto a punto, los componentes se comunican a través de colas y \emph{exchanges} definidos estratégicamente para cada escenario. Este enfoque incrementa notablemente la flexibilidad del sistema, ya que la incorporación de un nuevo nodo de procesamiento, o la eliminación de uno existente, no requiere modificar la lógica de negocio del resto de los participantes.  

Otro aspecto central es la asincronía. Gracias al middleware, los nodos no dependen de la disponibilidad inmediata de sus contrapartes, sino que pueden depositar mensajes en una cola para que el receptor los procese cuando corresponda. Esto aporta robustez frente a picos de carga y tolerancia a fallos parciales, ya que los datos no se pierden aunque un nodo se encuentre momentáneamente inactivo. Asimismo, las colas actúan como un mecanismo de \textit{buffering}, desacoplando el ritmo de producción y consumo de datos entre los distintos nodos.

La lógica de conexión se implementa en el componente \texttt{MQConnectionHandler}, ubicado en el paquete \texttt{shared}, que centraliza la configuración de colas, \emph{exchanges} y canales de comunicación. De este modo, se asegura un manejo uniforme y estandarizado de las operaciones de envío y recepción de mensajes. Sobre esta capa de mensajería se diseñó además un protocolo de aplicación específico que define la estructura de los mensajes para el envío de datasets, la transmisión de resultados y el manejo de errores, lo que permite garantizar la correcta interpretación de la información en todas las etapas del procesamiento.

Finalmente, para interactuar con el middleware se emplearon las interfaces provistas por la cátedra, complementadas con la implementación de pruebas unitarias exhaustivas que validaron su correcto funcionamiento bajo diferentes escenarios de carga. De esta manera, el middleware cumple con el requisito planteado en el enunciado de abstraer la comunicación entre los nodos del sistema distribuido, aportando una base sólida para la escalabilidad, el desacoplamiento y la mantenibilidad del sistema en su conjunto.

\subsection*{Esquemas de comunicación}

Durante el desarrollo se identificaron distintos patrones de comunicación, y para cada uno se diseñó una solución particular apoyada en las herramientas de RabbitMQ. A continuación, se describen los principales casos implementados:

\newpage

\subsubsection*{Comunicación mediante colas dedicadas}

En los nodos escalables, se definió una cola por cada instancia de nodo. Esto asegura la ausencia de \textit{race conditions} y permite direccionar la información de forma controlada, garantizando el funcionamiento correcto y balanceado del sistema.

Para decidir a qué cola enviar cada batch de datos se utilizaron dos estrategias:
\begin{enumerate}
    \item \textbf{Round Robin:} Cada emisor mantiene un contador que se incrementa en cada envío, distribuyendo los lotes de datos de forma equitativa entre las colas disponibles. Una vez alcanzado el último nodo, el contador retorna al primero.  
    Esta técnica fue utilizada en situaciones como:
    \begin{itemize}
        \item Servidor $\rightarrow$ Cleaners.
        \item Cleaners $\rightarrow$ Filters.
        \item Filters $\rightarrow$ Filters.
        \item Filters $\rightarrow$ Output Builder.
        \item Join Users $\rightarrow$ Join Stores.
        \item Filters $\rightarrow$ Map Year Month / Map Year Semester.
    \end{itemize}

    \item \textbf{Hashing por clave (Sharding):} Se empleó en los casos en que los datos debían ser dirigidos a un nodo específico según una clave.
    Por ejemplo, en la comunicación de:

    \begin{itemize}
        \item Cleaners de Usuarios $\rightarrow$ Joins de Usuarios.
    \end{itemize}
    
    La asignación de transacciones a los nodos de Join se resolvió aplicando una función hash sobre el ID de usuario.
    
    Concretamente, se utilizó el resto de la división entera del ID por la cantidad de nodos shardeados, lo que asegura que todas las transacciones de un mismo usuario lleguen al mismo nodo de Join.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{img/comunicacion1.png}
    \caption{Esquema de comunicación mediante colas dedicadas.}
\end{figure}

\newpage

\subsubsection*{Comunicación mediante exchanges}

En situaciones donde la misma información debía ser replicada en múltiples colas, se utilizó un \textbf{exchange} de RabbitMQ. Este patrón resultó especialmente útil en la \textbf{Query 2}, donde se debía dividir la información para dos subconsultas distintas: los ítems más vendidos y los que generaron mayor facturación.  

En este caso, el exchange distribuye la información procesada por el nodo \textit{Map Year Month} hacia las colas de:
\begin{itemize}
    \item Count Items.
    \item Sum Items.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\linewidth]{img/comunicacion2.png}
    \caption{Esquema de comunicación mediante exchanges.}
\end{figure}

\subsubsection*{Comunicación de nodos escalables hacia un nodo no escalable}

En escenarios donde múltiples nodos escalados debían enviar resultados a un nodo único no escalable (generalmente de tipo \textit{Reduce}), se diseñó una cola de recolección centralizada. Dicho nodo recopilaba toda la información y generaba el reporte final una vez recibidos los resultados de todos los emisores.  

Este esquema fue utilizado en situaciones como:
\begin{itemize}
    \item Filters $\rightarrow$ Count Purchases.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\linewidth]{img/comunicacion3.png}
    \caption{Esquema de comunicación de nodos escalables hacia un nodo único no escalable.}
\end{figure}

\subsubsection*{Comunicación 1 a 1}

Finalmente, en los casos donde la comunicación era estrictamente secuencial entre nodos no escalables, se implementaron colas directas de 1 a 1. Los principales casos fueron:
\begin{itemize}
    \item Count Items $\rightarrow$ Sort Items.
    \item Count Purchases $\rightarrow$ Sort Purchases.
    \item Sum Items $\rightarrow$ Sort Items.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\linewidth]{img/comunicacion4.png}
    \caption{Esquema de comunicación 1 a 1.}
\end{figure}

\subsection*{Detección y propagación de EOF}

Todos los controladores del sistema conocen tanto los nodos que les preceden como los que les suceden en la cadena de procesamiento. Esta información es fundamental para la correcta propagación de los mensajes de fin de flujo (\texttt{EOF}).

El mecanismo es el siguiente:
\begin{itemize}
    \item Cada nodo espera recibir la cantidad exacta de mensajes \texttt{EOF} correspondientes a los emisores que tiene detrás suyo. 
    \item Una vez que se han recibido todos los \texttt{EOF}, el nodo puede concluir que no habrá más información de entrada.
    \item En ese momento, genera y propaga su propio \texttt{EOF} hacia todos los nodos que le suceden, ya sea:
    \begin{itemize}
        \item Enviando a una cola directa (1 a 1).
        \item Replicando en un exchange.
        \item Distribuyendo por Round Robin entre varias colas.
    \end{itemize}
\end{itemize}

De esta manera, se garantiza que cada etapa del sistema procese exactamente todos los datos antes de finalizar, manteniendo un estado consistente y evitando pérdidas o confusiones en la comunicación.

\subsection*{Conclusión}

La combinación de estas estrategias de comunicación permitió cumplir con los requisitos de abstracción y desacoplamiento planteados, al mismo tiempo que se aprovecharon al máximo las capacidades de RabbitMQ. Gracias a esta arquitectura, el sistema puede escalar horizontalmente de manera sencilla y mantener la coherencia en el flujo de datos, asegurando un comportamiento correcto incluso en escenarios de alta concurrencia.
